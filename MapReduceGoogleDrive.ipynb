{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1q5Fb0rUB-Dh"
      },
      "source": [
        "# MapReduce\n",
        "The following Jupyter Notebook will:\n",
        "1. Download the PDF file from my google drive (using code from my [Medium Article](https://towardsdatascience.com/different-ways-to-connect-google-drive-to-a-google-colab-notebook-pt-1-de03433d2f7a))\n",
        "2. Select a chapter from the PDF file.\n",
        "3. Select the pages from 22 to 32 and save them in file1.txt\n",
        "4. Select the pages from 94 to 104 and save them in file2.txt\n",
        "5. Create a map.py file for the Map in **Map**Reduce\n",
        "6. Create a reduce.py file for the Reduce in Map**Reduce**\n",
        "7. Create a map_english.py file for mapping non-english words.\n",
        "  - Using NLTK - A natural Language library\n",
        "8. Run MapReduce for file1.txt and save it on a new output1.txt\n",
        "9. Run MapEmglishReduce for file2.txt and save it on a new output2.txt\n",
        "10. Combine both files and create a pdf."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8Cjl-z_zVzP"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KjMhazzBB2Va"
      },
      "outputs": [],
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import PyPDF2\n",
        "from fpdf import FPDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6Xh70yw3eG4"
      },
      "source": [
        "## 1. Dowload PDF from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_lrHco3t3Tfd"
      },
      "outputs": [],
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "file_id = '{FILE_ID}'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('Harry_Potter.pdf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plnYbywV5DvI"
      },
      "source": [
        "## 2. Select Chapter #3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9h1PUQDj355x"
      },
      "outputs": [],
      "source": [
        "def select_chapter(pdf_file, chapter_start_page,chapter_end_page):\n",
        "    \"\"\"Selects a chapter from a PDF.\n",
        "\n",
        "    Args:\n",
        "        pdf_file: name of the PDF file.\n",
        "        chapter_start_page: First page of the chapter\n",
        "        chapter_end_page: last page of the chapter\n",
        "\n",
        "    Returns:\n",
        "        A PDF object containing the selected chapter.\n",
        "    \"\"\"\n",
        "\n",
        "    with open(pdf_file, 'rb') as f:\n",
        "        pdf_reader = PyPDF2.PdfReader(f)\n",
        "\n",
        "        selected_chapter_pdf = PyPDF2.PdfWriter()\n",
        "\n",
        "        for page_number in range(chapter_start_page, chapter_end_page + 1):\n",
        "            page = pdf_reader.pages[page_number]\n",
        "            selected_chapter_pdf.add_page(page)\n",
        "\n",
        "    return selected_chapter_pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "desnekcA5Zfq"
      },
      "outputs": [],
      "source": [
        "pdf_file = 'Harry_Potter.pdf'\n",
        "chapter_start_page = 1085\n",
        "chapter_end_page = 1806\n",
        "\n",
        "selected_chapter_pdf = select_chapter(pdf_file, chapter_start_page,chapter_end_page)\n",
        "\n",
        "with open('chapter3.pdf', 'wb') as f:\n",
        "    selected_chapter_pdf.write(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45DhAMrVFUWZ"
      },
      "source": [
        "## 3.  Select from page 22 to 32 and create file1.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EHmw_P6e7kju"
      },
      "outputs": [],
      "source": [
        "start_page = 22\n",
        "end_page = 32\n",
        "\n",
        "with open('file1.txt', 'w') as f:\n",
        "    reader =  PyPDF2.PdfReader(\"chapter3.pdf\")\n",
        "    for page_number in range(start_page, end_page+1):\n",
        "            page = reader.pages[page_number]\n",
        "            f.write(page.extract_text())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2OnRD0aHCqA"
      },
      "source": [
        "## 4.  Select from page 94 to 104 and create file2.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "y9jBXBVED5nf"
      },
      "outputs": [],
      "source": [
        "start_page = 94\n",
        "end_page = 104\n",
        "\n",
        "with open('file2.txt', 'w') as f:\n",
        "    reader =  PyPDF2.PdfReader(\"chapter3.pdf\")\n",
        "    for page_number in range(start_page, end_page+1):\n",
        "            page = reader.pages[page_number]\n",
        "            f.write(page.extract_text())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNSb4wroHUZq"
      },
      "source": [
        "## 5. Map python file creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "plGxP5s4HReV",
        "outputId": "7e228cf6-200c-4f67-bc77-d57c6434b032"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing mapper.py\n"
          ]
        }
      ],
      "source": [
        "%%file mapper.py\n",
        "\n",
        "import sys\n",
        "import re\n",
        "\n",
        "for line in sys.stdin:\n",
        "    line = line.strip().lower()\n",
        "    words = re.findall(r'\\w+\\b', line)\n",
        "    for word in words:\n",
        "        print (f'{word}\\t 1')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfEWxxF3Hoiv"
      },
      "source": [
        "## 6. Reduce python file creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "7SOU4rXmHsHG",
        "outputId": "fce99963-bd29-4cf3-b328-332e31750f9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing reducer.py\n"
          ]
        }
      ],
      "source": [
        "%%file reducer.py\n",
        "\n",
        "from operator import itemgetter\n",
        "import sys\n",
        "\n",
        "with open(sys.argv[1], 'w') as f:\n",
        "  f.write(f\"{sys.argv[2]}\\n\")\n",
        "\n",
        "current_word = None\n",
        "current_count = 0\n",
        "word = None\n",
        "\n",
        "for line in sys.stdin:\n",
        "\n",
        "    word, count = line.split('\\t', 1)\n",
        "\n",
        "    try:\n",
        "        count = int(count)\n",
        "    except ValueError:\n",
        "\n",
        "        continue\n",
        "\n",
        "    if current_word == word:\n",
        "        current_count += count\n",
        "    else:\n",
        "        if current_word:\n",
        "            with open(sys.argv[1], 'a') as f:\n",
        "              f.write(f'{current_word}\\t{current_count}\\n')\n",
        "        current_count = count\n",
        "        current_word = word\n",
        "\n",
        "\n",
        "if current_word == word:\n",
        "  with open(sys.argv[1], 'a') as f:\n",
        "            f.write(f'{current_word}\\t{current_count}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGee47N4IGYm"
      },
      "source": [
        "## 7. Mapper Non English file creation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3zIqIev-IKIs",
        "outputId": "4f123245-8d3e-4b84-ea75-3f515990e3f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing mapper_english.py\n"
          ]
        }
      ],
      "source": [
        "## Same as mapper.py but adding the nltk library for non english words\n",
        "\n",
        "%%file mapper_english.py\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import words\n",
        "\n",
        "\n",
        "nltk.download('words')\n",
        "\n",
        "english_words = set(words.words())\n",
        "\n",
        "\n",
        "for line in sys.stdin:\n",
        "    line = line.strip().lower()\n",
        "    words = re.findall(r'\\w+\\b', line)\n",
        "\n",
        "    for word in words:\n",
        "        if word not in english_words:\n",
        "          print (f'{word}\\t 1')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtPUea_DH6wV"
      },
      "source": [
        "### Making the files executable!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YTjWPUYtH6AT"
      },
      "outputs": [],
      "source": [
        "!chmod +x mapper.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "uGV_B4esIC6-"
      },
      "outputs": [],
      "source": [
        "!chmod +x reducer.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "pUUZadTdJXLs"
      },
      "outputs": [],
      "source": [
        "!chmod +x mapper_english.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIuopzO9WT6i"
      },
      "source": [
        "## 8. Running MapReducer for file1.txt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3583JVVtWghz"
      },
      "outputs": [],
      "source": [
        "!cat file1.txt | ./mapper.py | sort | ./reducer.py output1.txt MapReduce_All| sort"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BImdcINxXBjO"
      },
      "source": [
        "## 9. Running MapReducer for file2.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "peFIuCyzXHvc",
        "outputId": "f887f95e-296f-4155-8cd3-473858e08538"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        }
      ],
      "source": [
        "!cat file2.txt | ./mapper_english.py | sort | ./reducer.py output2.txt MapReduce_Non_English_NLTK| sort"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8fA-ctJXMYo"
      },
      "source": [
        "## 10. Saving as a PDF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jWuhW0LUYRpf",
        "outputId": "4f724c14-c2cb-45ba-a1c9-809785c631d1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pdf = FPDF()\n",
        "pdf.add_page()\n",
        "\n",
        "pdf.set_font(\"Arial\", size = 12)\n",
        "\n",
        "f = open(\"output1.txt\", \"r\")\n",
        "f2 = open(\"output2.txt\", \"r\")\n",
        "\n",
        "pdf.cell(200, 15, txt = 'MapReduce File 1', ln = 1, align = 'C')\n",
        "for x in f:\n",
        "  pdf.cell(200, 10, txt = x, ln = 1, align = 'L')\n",
        "\n",
        "pdf.cell(200, 15, txt = 'MapReduce File 2 - Non English', ln = 1, align = 'C')\n",
        "\n",
        "for x in f2:\n",
        "  pdf.cell(200, 10, txt = x, ln = 1, align = 'L')\n",
        "\n",
        "pdf.output(\"Final_output.pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaCoPFKTaTIr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
